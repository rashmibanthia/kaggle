{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Nvidia Apex\n",
    "#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a\n",
    "\n",
    "#pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" NVIDIA-apex-39e153a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n",
      "/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "#from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "\n",
    "from apex import amp\n",
    "import shutil\n",
    "import regex as re\n",
    "\n",
    "device=torch.device('cuda')\n",
    "\n",
    "#package_dir_a = '../input/pytorchpretrainedgpt2/pytorch-pretrained-gpt2/pytorch-pretrained-gpt2/'\n",
    "#package_dir_a = '../data/pytorch-pretrained-gpt2/'\n",
    "#package_dir_a = '../data/pytorch-pretrained-BERT_latest/'\n",
    "\n",
    "package_dir_a = '../data/pytorch-pretrained-gpt2/'\n",
    "sys.path.insert(0, package_dir_a)\n",
    "\n",
    "from pytorch_pretrained_bert import GPT2Tokenizer, GPT2ClassificationHeadModel\n",
    "from pytorch_pretrained_bert import OpenAIAdam\n",
    "\n",
    "\n",
    "# This is the GPT2 configuration file\n",
    "from pytorch_pretrained_bert import GPT2Config\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "Data_dir = '../data/'\n",
    "Input_dir = Data_dir\n",
    "WORK_DIR = '.'\n",
    "\n",
    "FOLD_NUM = 0\n",
    "#Data_dir=\"../input/jigsaw-unintended-bias-in-toxicity-classification/\"\n",
    "#Input_dir = Data_dir\n",
    "#WORK_DIR = '.'\n",
    "\n",
    "SEED = 1234\n",
    "TRAIN_SAMPLE_SEED = 1234\n",
    "MAX_SEQ_LENGTH = 220\n",
    "\n",
    "#GPT2_MODEL_PATH = '../input/gpt2-models/'\n",
    "GPT2_MODEL_PATH = '../data/gpt2-models_kaggle/'\n",
    "    \n",
    "TOKENIZER_PATH = '../data/gpt2-models_kaggle/'\n",
    "GPT2_CONFIG_PATH = '../data/gpt2-models_kaggle/config.json'\n",
    "\n",
    "shutil.copyfile(GPT2_MODEL_PATH + 'config.json', WORK_DIR + 'config.json')\n",
    "\n",
    "num_to_load= 1804874 #1000000 #1704874 \n",
    "#valid_size=  100000 \n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "#gpt2_config = GPT2Config('../input/gpt2-models/config.json')\n",
    "gpt2_config = GPT2Config(GPT2_CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loaded 1804874 records\n"
     ]
    }
   ],
   "source": [
    "#train_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\")).sample(num_to_load+valid_size,random_state=TRAIN_SAMPLE_SEED)\n",
    "train_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\"))\n",
    "print('Train: loaded %d records' % len(train_df))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train_df['comment_text'] = train_df['comment_text'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/pytorch-pretrained-gpt2/pytorch_pretrained_bert/tokenization_gpt2.py:146: ResourceWarning: unclosed file <_io.TextIOWrapper name='../data/gpt2-models_kaggle/vocab.json' mode='r' encoding='UTF-8'>\n",
      "  self.encoder = json.load(open(vocab_file))\n",
      "../data/pytorch-pretrained-gpt2/pytorch_pretrained_bert/tokenization_gpt2.py:151: ResourceWarning: unclosed file <_io.TextIOWrapper name='../data/gpt2-models_kaggle/merges.txt' mode='r' encoding='utf-8'>\n",
      "  bpe_data = open(merges_file, encoding='utf-8').read().split('\\n')[1:-1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40d2b68308c4434b0b1b719a7a29a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1804874), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "47658\n"
     ]
    }
   ],
   "source": [
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    max_seq_length -=2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in tqdm_notebook(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids(tokens_a)+[0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    print(longer)\n",
    "    return np.array(all_tokens)\n",
    "\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('../input/gpt2-models/')\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "sequences = convert_lines(train_df['comment_text'], MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.fillna(0)\n",
    "# List all identities\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "y_columns=['target']\n",
    "\n",
    "train_df = train_df.drop(['comment_text'],axis=1)\n",
    "# convert target to 0,1\n",
    "train_df['target']=(train_df['target']>=0.5).astype(float)  \n",
    "\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = ['asian', 'atheist', \n",
    "       'bisexual', 'black', 'buddhist', 'christian', 'female',\n",
    "       'heterosexual', 'hindu', 'homosexual_gay_or_lesbian',\n",
    "       'intellectual_or_learning_disability', 'jewish', 'latino', 'male',\n",
    "       'muslim', 'other_disability', 'other_gender',\n",
    "       'other_race_or_ethnicity', 'other_religion',\n",
    "       'other_sexual_orientation', 'physical_disability',\n",
    "       'psychiatric_or_mental_illness', 'transgender', 'white']\n",
    "    \n",
    "subgroup_bool_train = train_df[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train_df[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "#bpsn = ((subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train)).astype(int)   +  \\\n",
    "# ((~subgroup_bool_train.values.sum(axis=1).astype(bool)  & toxic_bool_train)).astype(int) \n",
    "\n",
    "\n",
    "# Overall\n",
    "weights = np.ones((len(train_df),))\n",
    "# Subgroup negative\n",
    "weights += subgroup_negative_mask #bpsn\n",
    "loss_weight = 1.0 / weights.mean()\n",
    "\n",
    "train_df['weights'] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443899, 218) (1443899, 8) (360975, 218) (360975, 8) (1804874, 45)\n"
     ]
    }
   ],
   "source": [
    "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=47).split(sequences, train_df[y_columns].values[:,0]))\n",
    "\n",
    "y_columns=['target', 'weights']\n",
    "y_columns = ['target', 'weights', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']\n",
    "\n",
    "len_train = 0\n",
    "len_val = 0\n",
    "for fld, (train_index, val_index) in enumerate(splits):\n",
    "    if fld == FOLD_NUM:\n",
    "        len_train = len(train_index)\n",
    "        len_val = len(val_index)\n",
    "        break\n",
    "        \n",
    "train_idx = np.zeros((len_train))\n",
    "val_idx = np.zeros((len_val))\n",
    "\n",
    "for fld, (train_index, val_index) in enumerate(splits):\n",
    "    if fld == FOLD_NUM:\n",
    "        train_idx = train_index\n",
    "        val_idx = val_index\n",
    "        break\n",
    "        \n",
    "X = sequences[train_idx]\n",
    "y = train_df[y_columns].values[train_idx]\n",
    "\n",
    "X_val = sequences[val_index]\n",
    "y_val = train_df[y_columns].values[val_index]\n",
    "\n",
    "print(X.shape, y.shape, X_val.shape, y_val.shape, train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_columns=['target', 'weights']\n",
    "# y_columns = ['target', 'weights', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']\n",
    "    \n",
    "# X = sequences[:num_to_load]                \n",
    "# y = train_df[y_columns].values[:num_to_load]\n",
    "# X_val = sequences[num_to_load:]                \n",
    "# y_val = train_df[y_columns].values[num_to_load:]\n",
    "\n",
    "# print(X.shape, y.shape, X_val.shape, y_val.shape, train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df=train_df.tail(valid_size).copy()\n",
    "# train_df=train_df.head(num_to_load)\n",
    "# print(X.shape, y.shape, X_val.shape, y_val.shape, train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class LenMatchBatchSampler(data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            count_zeros = torch.sum(self.sampler.data_source[idx][0] == 0)\n",
    "            count_zeros = int(count_zeros / 64) \n",
    "            if len(buckets[count_zeros]) == 0:  buckets[count_zeros] = []\n",
    "\n",
    "            buckets[count_zeros].append(idx)\n",
    "\n",
    "            if len(buckets[count_zeros]) == self.batch_size:\n",
    "                batch = list(buckets[count_zeros])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[count_zeros] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "        assert len(self) == yielded, \"produced an incorrect number of batches. expected %i, but yielded %i\" %(len(self), yielded)\n",
    "\n",
    "def trim_tensors(tsrs):\n",
    "    max_len = torch.max(torch.sum( (tsrs[0] != 0  ), 1))\n",
    "    if max_len > 2: \n",
    "        tsrs = [tsr[:, :max_len] for tsr in tsrs] \n",
    "    return tsrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = \"gpt2_pytorch_mymodel_fold\"\n",
    "output_model_file = output_model_file + str(FOLD_NUM) + '.bin'\n",
    "\n",
    "\n",
    "lr= 2e-5 # 2e-5\n",
    "batch_size = 32\n",
    "EPOCHS = 1\n",
    "accumulation_steps=1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "model = GPT2ClassificationHeadModel.from_pretrained(GPT2_MODEL_PATH, clf_dropout=0.2, n_class=len(y_columns))\n",
    "\n",
    "model.zero_grad()\n",
    "model = model.to(device)\n",
    "param_optimizer = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long),\n",
    "                                            torch.from_numpy(np.array(X>0, dtype=np.uint8)),\n",
    "                                            torch.zeros(X.shape),\n",
    "                                            torch.tensor(y,dtype=torch.float))\n",
    "\n",
    "ran_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "\n",
    "len_sampler = LenMatchBatchSampler(ran_sampler, batch_size = batch_size, drop_last = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "\n",
    "num_train_optimization_steps = int(EPOCHS*len(train_dataset)/batch_size/accumulation_steps)\n",
    "\n",
    "optimizer = OpenAIAdam(optimizer_grouped_parameters, \n",
    "                       lr=lr,\n",
    "                       warmup=0.05,\n",
    "                       t_total=num_train_optimization_steps)\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9269002138952298"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data, targets):  #data=predictions, target = groundtruth\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:,1:2])(data[:,:1],targets[:,:1]) #target\n",
    "    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:,2:],targets[:,2:]) #aux targets\n",
    "    #bce_loss_2  = nn.KLDivLoss()(torch.log_softmax(data[:,2:],1),targets[:,2:]) #aux targets\n",
    "    return (bce_loss_1 * loss_weight) + bce_loss_2\n",
    "    \n",
    "    \n",
    "    \n",
    "#UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
    "#warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d385571bd9bc4837b212b8fad44c5c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def mygc():\n",
    "    gc.collect()\n",
    "    return None\n",
    "\n",
    "tq = tqdm_notebook(range(EPOCHS))\n",
    "for epoch in tq:\n",
    "    #train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler = len_sampler) \n",
    "    \n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    lossf=None\n",
    "    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    #for i,(x_batch, y_batch) in tk0:\n",
    "    for i,batch in tk0: \n",
    "        tsrs = trim_tensors(batch)\n",
    "        b_input_ids, b_input_mask, b_segment_ids, b_label = tuple(t.to(device) for t in tsrs)\n",
    "        \n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        #y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "        #loss = custom_loss(y_pred,y_batch.to(device))\n",
    "        \n",
    "        y_pred = model(b_input_ids.to(device))\n",
    "        loss = custom_loss(y_pred,b_label.to(device))\n",
    "        \n",
    "        #del y_pred,y_batch\n",
    "        gc.collect()\n",
    "        #break\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        \n",
    "         \n",
    "        \n",
    "        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()\n",
    "        if lossf:\n",
    "            lossf = 0.98*lossf+0.02*loss.item()\n",
    "        else:\n",
    "            lossf = loss.item()\n",
    "        tk0.set_postfix(loss = lossf)\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        #avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
    "        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (b_label[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
    "        \n",
    "        mygc()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #if (i>300):\n",
    "        #    break\n",
    "    \n",
    "    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n",
    " \n",
    "    \n",
    "torch.save(model.state_dict(), output_model_file) \n",
    "#100% 1/1 [4:32:01<00:00, 16321.62s/it, avg_accuracy=0.945, avg_loss=0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache() \n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ClassificationHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "        (ln_2): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (linear): Linear(in_features=1536, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run validation\n",
    "# The following 2 lines are not needed but show how to download the model for prediction\n",
    "model = GPT2ClassificationHeadModel.from_pretrained(GPT2_MODEL_PATH, clf_dropout=0.2, n_class=len(y_columns))\n",
    "model.load_state_dict(torch.load(output_model_file ))\n",
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b62649afe894a878557d53fe6e7ef73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11281), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_preds = np.zeros((len(X_val)))\n",
    "valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n",
    "\n",
    "tk0 = tqdm_notebook(valid_loader)\n",
    "for i,(x_batch,)  in enumerate(tk0):\n",
    "    pred = model(x_batch.to(device))\n",
    "    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From baseline kernel\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]>0.5\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "\n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]>0.5]\n",
    "    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n",
    "    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label]>0.5, examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n",
    "    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label]>0.5, examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bnsp_auc  bpsn_auc                       subgroup  subgroup_auc  \\\n",
      "2  0.960662  0.890127      homosexual_gay_or_lesbian      0.846586   \n",
      "6  0.968825  0.873024                          black      0.854669   \n",
      "7  0.964061  0.893505                          white      0.859274   \n",
      "5  0.959257  0.914816                         muslim      0.875753   \n",
      "4  0.950636  0.935091                         jewish      0.889653   \n",
      "0  0.963746  0.942730                           male      0.928077   \n",
      "3  0.946463  0.962159                      christian      0.929321   \n",
      "1  0.960651  0.950449                         female      0.932405   \n",
      "8  0.969740  0.935161  psychiatric_or_mental_illness      0.933825   \n",
      "\n",
      "   subgroup_size  \n",
      "2           2064  \n",
      "6           2815  \n",
      "7           4780  \n",
      "5           3882  \n",
      "4           1448  \n",
      "0           8081  \n",
      "3           7068  \n",
      "1          10014  \n",
      "8            785  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9348877675010141"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'model1'\n",
    "test_df = train_df.iloc[val_idx].copy()\n",
    "\n",
    "identity_columns = [\n",
    "     'male',  'female',  'homosexual_gay_or_lesbian', 'christian', 'jewish','muslim', 'black', 'white', 'psychiatric_or_mental_illness' ]\n",
    "   \n",
    "test_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "TOXICITY_COLUMN = 'target'\n",
    "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\n",
    "print(bias_metrics_df)\n",
    "get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_oof = torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
    "\n",
    "\n",
    "np.save('results_oof_fold' + str(FOLD_NUM) + '.npy',results_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360975,) (360975,)\n"
     ]
    }
   ],
   "source": [
    "print(valid_preds.shape, results_oof.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eaba9bcfca4183b3d0daabf26c78de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=97320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2560\n"
     ]
    }
   ],
   "source": [
    "#Inference on test set \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(Data_dir,\"test.csv\"))\n",
    "test_df['comment_text'] = test_df['comment_text'].astype(str) \n",
    "X_test = convert_lines(test_df[\"comment_text\"].fillna(\"DUMMY_VALUE\"), MAX_SEQ_LENGTH, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e21c5ada6f4c858b77b1c0a9925005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3042), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = np.zeros((len(X_test)))\n",
    "test = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)\n",
    "tk0 = tqdm(test_loader)\n",
    "for i, (x_batch,) in enumerate(tk0):\n",
    "    pred = model(x_batch.to(device))\n",
    "    test_preds[i * 32:(i + 1) * 32] = pred[:, 0].detach().cpu().squeeze().numpy()\n",
    "\n",
    "test_pred = torch.sigmoid(torch.tensor(test_preds)).numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_df['id'],\n",
    "    'prediction': test_pred\n",
    "})\n",
    "\n",
    "\n",
    "submission.to_csv( 'submission_fold' + str(FOLD_NUM) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>0.003795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>0.980431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7000005</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7000006</td>\n",
       "      <td>0.001694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7000007</td>\n",
       "      <td>0.002621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7000008</td>\n",
       "      <td>0.058993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7000009</td>\n",
       "      <td>0.020489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7000010</td>\n",
       "      <td>0.000773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7000011</td>\n",
       "      <td>0.122313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7000012</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7000013</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7000014</td>\n",
       "      <td>0.000636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7000015</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7000016</td>\n",
       "      <td>0.011597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7000017</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7000018</td>\n",
       "      <td>0.203866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7000019</td>\n",
       "      <td>0.006290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7000020</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7000021</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7000022</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7000023</td>\n",
       "      <td>0.510527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7000024</td>\n",
       "      <td>0.842475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7000025</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7000026</td>\n",
       "      <td>0.040465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7000027</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7000028</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7000029</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97290</th>\n",
       "      <td>7097290</td>\n",
       "      <td>0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97291</th>\n",
       "      <td>7097291</td>\n",
       "      <td>0.263031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97292</th>\n",
       "      <td>7097292</td>\n",
       "      <td>0.177526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97293</th>\n",
       "      <td>7097293</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97294</th>\n",
       "      <td>7097294</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97295</th>\n",
       "      <td>7097295</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97296</th>\n",
       "      <td>7097296</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97297</th>\n",
       "      <td>7097297</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97298</th>\n",
       "      <td>7097298</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97299</th>\n",
       "      <td>7097299</td>\n",
       "      <td>0.006641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97300</th>\n",
       "      <td>7097300</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97301</th>\n",
       "      <td>7097301</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97302</th>\n",
       "      <td>7097302</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97303</th>\n",
       "      <td>7097303</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97304</th>\n",
       "      <td>7097304</td>\n",
       "      <td>0.114171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97305</th>\n",
       "      <td>7097305</td>\n",
       "      <td>0.081666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97306</th>\n",
       "      <td>7097306</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97307</th>\n",
       "      <td>7097307</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97308</th>\n",
       "      <td>7097308</td>\n",
       "      <td>0.006438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97309</th>\n",
       "      <td>7097309</td>\n",
       "      <td>0.006798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97310</th>\n",
       "      <td>7097310</td>\n",
       "      <td>0.009746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97311</th>\n",
       "      <td>7097311</td>\n",
       "      <td>0.005002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97312</th>\n",
       "      <td>7097312</td>\n",
       "      <td>0.106877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97313</th>\n",
       "      <td>7097313</td>\n",
       "      <td>0.075721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97314</th>\n",
       "      <td>7097314</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97315</th>\n",
       "      <td>7097315</td>\n",
       "      <td>0.007548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97316</th>\n",
       "      <td>7097316</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97317</th>\n",
       "      <td>7097317</td>\n",
       "      <td>0.013020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97318</th>\n",
       "      <td>7097318</td>\n",
       "      <td>0.060529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97319</th>\n",
       "      <td>7097319</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prediction\n",
       "0      7000000    0.002611\n",
       "1      7000001    0.000039\n",
       "2      7000002    0.003795\n",
       "3      7000003    0.000729\n",
       "4      7000004    0.980431\n",
       "5      7000005    0.000064\n",
       "6      7000006    0.001694\n",
       "7      7000007    0.002621\n",
       "8      7000008    0.058993\n",
       "9      7000009    0.020489\n",
       "10     7000010    0.000773\n",
       "11     7000011    0.122313\n",
       "12     7000012    0.000187\n",
       "13     7000013    0.000143\n",
       "14     7000014    0.000636\n",
       "15     7000015    0.000291\n",
       "16     7000016    0.011597\n",
       "17     7000017    0.000134\n",
       "18     7000018    0.203866\n",
       "19     7000019    0.006290\n",
       "20     7000020    0.000997\n",
       "21     7000021    0.000098\n",
       "22     7000022    0.000057\n",
       "23     7000023    0.510527\n",
       "24     7000024    0.842475\n",
       "25     7000025    0.000267\n",
       "26     7000026    0.040465\n",
       "27     7000027    0.000171\n",
       "28     7000028    0.000685\n",
       "29     7000029    0.000993\n",
       "...        ...         ...\n",
       "97290  7097290    0.001320\n",
       "97291  7097291    0.263031\n",
       "97292  7097292    0.177526\n",
       "97293  7097293    0.000021\n",
       "97294  7097294    0.000207\n",
       "97295  7097295    0.000368\n",
       "97296  7097296    0.000047\n",
       "97297  7097297    0.000257\n",
       "97298  7097298    0.000181\n",
       "97299  7097299    0.006641\n",
       "97300  7097300    0.000123\n",
       "97301  7097301    0.000940\n",
       "97302  7097302    0.000066\n",
       "97303  7097303    0.000333\n",
       "97304  7097304    0.114171\n",
       "97305  7097305    0.081666\n",
       "97306  7097306    0.000310\n",
       "97307  7097307    0.000025\n",
       "97308  7097308    0.006438\n",
       "97309  7097309    0.006798\n",
       "97310  7097310    0.009746\n",
       "97311  7097311    0.005002\n",
       "97312  7097312    0.106877\n",
       "97313  7097313    0.075721\n",
       "97314  7097314    0.000776\n",
       "97315  7097315    0.007548\n",
       "97316  7097316    0.000033\n",
       "97317  7097317    0.013020\n",
       "97318  7097318    0.060529\n",
       "97319  7097319    0.000149\n",
       "\n",
       "[97320 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
